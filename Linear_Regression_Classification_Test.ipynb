{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close    4315.32\n",
      "high     4315.32\n",
      "Name: 39, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candle_number_to_calculate = 3\n",
    "\n",
    "def fetchCryptoData():\n",
    "    exchange = ccxt.binance()\n",
    "\n",
    "    symbol = 'BTC/USDT'\n",
    "    timeframe = '3m'\n",
    "\n",
    "    # Fetch OHLCV data (public data)\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe,20231001)\n",
    "\n",
    "    # Convert the data to a DataFrame\n",
    "    df = pd.DataFrame(ohlcv,columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "    # Convert timestamp to a human-readable format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # Drop the integer index column\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = fetchCryptoData()\n",
    "print(df.loc[39,['close','high']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, p):\n",
    "    min_val = x[-p:].min()\n",
    "    max_val = x[-p:].max()\n",
    "\n",
    "    scaled_column = (x - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_column\n",
    "\n",
    "def add_talib_indicators(data):\n",
    "    # RSI\n",
    "    data['rs'] = talib.RSI(data['close'], timeperiod=28)\n",
    "    data['rf'] = talib.RSI(data['close'], timeperiod=14)\n",
    "    # ROC\n",
    "    data['os'] = talib.ROC(data['close'], timeperiod=28)\n",
    "    data['of'] = talib.ROC(data['close'], timeperiod=14)\n",
    "\n",
    "    # CCI\n",
    "    data['cs'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=28)\n",
    "    data['cf'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=14)\n",
    "\n",
    "    # MOM\n",
    "    data['ms'] = scale(talib.MOM(data['close'], timeperiod=28),63) *100\n",
    "    data['mf'] = scale(talib.MOM(data['close'], timeperiod=14),63) *100\n",
    "\n",
    "    data['rs'] = np.nan_to_num(data['rs'])\n",
    "    data['os'] = np.nan_to_num(data['os'])\n",
    "    data['cs'] = np.nan_to_num(data['cs'])\n",
    "    data['ms'] = np.nan_to_num(data['ms'])\n",
    "\n",
    "    data['rf'] = np.nan_to_num(data['rf'])\n",
    "    data['of'] = np.nan_to_num(data['of'])\n",
    "    data['cf'] = np.nan_to_num(data['cf'])\n",
    "    data['mf'] = np.nan_to_num(data['mf'])\n",
    "\n",
    "    return data\n",
    "\n",
    "df = add_talib_indicators(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_1_slow(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rs']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['os']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cs']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['ms']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rs']+dataframe['os']+dataframe['cs']+dataframe['ms'])/4\n",
    "    \n",
    "\n",
    "def calculate_feature_2_fast(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rf']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['of']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cf']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['mf']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rf']+dataframe['of']+dataframe['cf']+dataframe['mf'])/4\n",
    "\n",
    "def calculate_regression_value(dataframe):\n",
    "    dataframe['actual_regression'] = -1 #Sell Signal\n",
    "    condition = (dataframe['close'].shift(-candle_number_to_calculate) - dataframe['close']) > 0\n",
    "    dataframe.loc[condition, 'actual_regression'] = 1 #Buy Signal\n",
    "    return dataframe['actual_regression']\n",
    "\n",
    "df['actual_regression'] = np.nan_to_num(calculate_regression_value(df))\n",
    "df['feature_slow'] = np.nan_to_num(calculate_feature_1_slow(\"All\",df))\n",
    "df['feature_fast'] = np.nan_to_num(calculate_feature_2_fast(\"All\",df))\n",
    "df['feature_combination'] = df['feature_slow'] * df['feature_fast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data And Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.534\n",
      "Training Accuracy : 0.6832151300236406 ===== Testing Accuracy : 0.8085106382978723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    # Generate some sample data\n",
    "    filter_index = df[(df['feature_slow'] == 0) | (df['feature_fast'] == 0)].index\n",
    "\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "    # Drop X 0 and last 3 candle\n",
    "    X = X.drop(filter_index)\n",
    "    X = X.iloc[:, X.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    # Drop Y 0 and last 3 candle\n",
    "    y = y.drop(filter_index)\n",
    "    y = y.iloc[:, y.columns.isin(['actual_regression'])]\n",
    "\n",
    "    test_data = df[['feature_slow', 'feature_fast','close','rs']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(\n",
    "                          kernel='rbf',\n",
    "                          C=100,\n",
    "                          gamma='auto',\n",
    "                          random_state=42,\n",
    "                          probability=True,\n",
    "                          cache_size=1,\n",
    "                          )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, \n",
    "                                      min_samples_leaf=50,\n",
    "                                      oob_score=True,\n",
    "                                      random_state=42)\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "                                                  ('svm', svm_classifier), \n",
    "                                                  ('rf', rf_model),\n",
    "                                                  ], voting='hard')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[450:500,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volatility_filter\n",
      " 1.0    37\n",
      "-1.0    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def volatilifyFilter(dataframe):\n",
    "    # Define BB windows \n",
    "    bb_window = 20\n",
    "    bb_dev = 2\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    upper_band , middle_band, lower_band = talib.BBANDS(dataframe['close'],timeperiod=bb_window,nbdevup=bb_dev,nbdevdn=bb_dev)\n",
    "\n",
    "    # Calculate ATR\n",
    "\n",
    "    # Define threshold for atr\n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] < lower_band)\n",
    "        ),\n",
    "        'volatility_filter'] = 1\n",
    "    \n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] > upper_band)\n",
    "        ),\n",
    "        'volatility_filter'] = -1\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df = volatilifyFilter(df)\n",
    "print(df['volatility_filter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftuser/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.948\n",
      "Training Accuracy : 0.5861297539149888 ===== Testing Accuracy : 0.6\n"
     ]
    }
   ],
   "source": [
    "# Second Model\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast'])]\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    test_data = df[['feature_slow', 'feature_fast']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(kernel='poly',\n",
    "                        C=100,\n",
    "                        gamma='auto',\n",
    "                        random_state=42,\n",
    "                        probability=True,\n",
    "                        tol=0.1,\n",
    "                        cache_size=1,\n",
    "                        max_iter=100,\n",
    "                        degree=3\n",
    "                        )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                      oob_score=True,\n",
    "                                      )\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[('svm', svm_classifier), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train_std, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[0:50,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n"
     ]
    }
   ],
   "source": [
    "# def adaptiveTrendFinder(self,dataframe:DataFrame):\n",
    "#     # Variable Can Modify\n",
    "#     devMultiplier = 2.0\n",
    "\n",
    "#     # Calculate Deviation,PersionR,Slope,Intercept\n",
    "#     stdDev01, pearsonR01, slope01, intercept01 = self.calcDev(self.periods[1],dataframe)\n",
    "#     stdDev02, pearsonR02, slope02, intercept02 = self.calcDev(self.periods[2],dataframe)\n",
    "#     stdDev03, pearsonR03, slope03, intercept03 = self.calcDev(self.periods[3],dataframe)\n",
    "#     stdDev04, pearsonR04, slope04, intercept04 = self.calcDev(self.periods[4],dataframe)\n",
    "#     stdDev05, pearsonR05, slope05, intercept05 = self.calcDev(self.periods[5],dataframe)\n",
    "#     stdDev06, pearsonR06, slope06, intercept06 = self.calcDev(self.periods[6],dataframe)\n",
    "#     stdDev07, pearsonR07, slope07, intercept07 = self.calcDev(self.periods[7],dataframe)\n",
    "#     stdDev08, pearsonR08, slope08, intercept08 = self.calcDev(self.periods[8],dataframe)\n",
    "#     stdDev09, pearsonR09, slope09, intercept09 = self.calcDev(self.periods[9],dataframe)\n",
    "#     stdDev10, pearsonR10, slope10, intercept10 = self.calcDev(self.periods[10],dataframe)\n",
    "#     stdDev11, pearsonR11, slope11, intercept11 = self.calcDev(self.periods[11],dataframe)\n",
    "#     stdDev12, pearsonR12, slope12, intercept12 = self.calcDev(self.periods[12],dataframe)\n",
    "#     stdDev13, pearsonR13, slope13, intercept13 = self.calcDev(self.periods[13],dataframe)\n",
    "#     stdDev14, pearsonR14, slope14, intercept14 = self.calcDev(self.periods[14],dataframe)\n",
    "#     stdDev15, pearsonR15, slope15, intercept15 = self.calcDev(self.periods[15],dataframe)\n",
    "#     stdDev16, pearsonR16, slope16, intercept16 = self.calcDev(self.periods[16],dataframe)\n",
    "#     stdDev17, pearsonR17, slope17, intercept17 = self.calcDev(self.periods[17],dataframe)\n",
    "#     stdDev18, pearsonR18, slope18, intercept18 = self.calcDev(self.periods[18],dataframe)\n",
    "#     stdDev19, pearsonR19, slope19, intercept19 = self.calcDev(self.periods[19],dataframe)\n",
    "\n",
    "#     # Find the highest Pearson's R\n",
    "#     # float highestPearsonR = pearsonR01\n",
    "#     highestPearsonR = max(pearsonR01, pearsonR02, pearsonR03, pearsonR04, pearsonR05, pearsonR06, pearsonR07, pearsonR08, pearsonR09, pearsonR10, pearsonR11, pearsonR12, pearsonR13, pearsonR14, pearsonR15, pearsonR16, pearsonR17, pearsonR18, pearsonR19)\n",
    "\n",
    "#     # Determine selected length, slope, intercept, and deviations\n",
    "#     detectedPeriod  = 0\n",
    "#     detectedSlope   = 0\n",
    "#     detectedIntrcpt = 0\n",
    "#     detectedStdDev  = 0\n",
    "\n",
    "#     if highestPearsonR == pearsonR01:\n",
    "#         detectedPeriod = self.periods[1]\n",
    "#         detectedSlope = slope01\n",
    "#         detectedIntrcpt = intercept01\n",
    "#         detectedStdDev = stdDev01\n",
    "#     elif highestPearsonR == pearsonR02:\n",
    "#         detectedPeriod = self.periods[2] \n",
    "#         detectedSlope = slope02\n",
    "#         detectedIntrcpt = intercept02\n",
    "#         detectedStdDev = stdDev02\n",
    "#     elif highestPearsonR == pearsonR03:\n",
    "#         detectedPeriod = self.periods[3]  \n",
    "#         detectedSlope = slope03\n",
    "#         detectedIntrcpt = intercept03\n",
    "#         detectedStdDev = stdDev03\n",
    "#     elif highestPearsonR == pearsonR04:\n",
    "#         detectedPeriod = self.periods[4]  \n",
    "#         detectedSlope = slope04\n",
    "#         detectedIntrcpt = intercept04\n",
    "#         detectedStdDev = stdDev04\n",
    "#     elif highestPearsonR == pearsonR05:\n",
    "#         detectedPeriod = self.periods[5]  \n",
    "#         detectedSlope = slope05\n",
    "#         detectedIntrcpt = intercept05\n",
    "#         detectedStdDev = stdDev05\n",
    "#     elif highestPearsonR == pearsonR06:\n",
    "#         detectedPeriod = self.periods[6]       \n",
    "#         detectedSlope = slope06\n",
    "#         detectedIntrcpt = intercept06\n",
    "#         detectedStdDev = stdDev06\n",
    "#     elif highestPearsonR == pearsonR07:\n",
    "#         detectedPeriod = self.periods[7]      \n",
    "#         detectedSlope = slope07\n",
    "#         detectedIntrcpt = intercept07\n",
    "#         detectedStdDev = stdDev07\n",
    "#     elif highestPearsonR == pearsonR08:\n",
    "#         detectedPeriod = self.periods[8]       \n",
    "#         detectedSlope = slope08\n",
    "#         detectedIntrcpt = intercept08\n",
    "#         detectedStdDev = stdDev08\n",
    "#     elif highestPearsonR == pearsonR09:\n",
    "#         detectedPeriod = self.periods[9]       \n",
    "#         detectedSlope = slope09\n",
    "#         detectedIntrcpt = intercept09\n",
    "#         detectedStdDev = stdDev09\n",
    "#     elif highestPearsonR == pearsonR10:\n",
    "#         detectedPeriod = self.periods[10]\n",
    "#         detectedSlope = slope10\n",
    "#         detectedIntrcpt = intercept10\n",
    "#         detectedStdDev = stdDev10\n",
    "#     elif highestPearsonR == pearsonR11:\n",
    "#         detectedPeriod = self.periods[11]\n",
    "#         detectedSlope = slope11\n",
    "#         detectedIntrcpt = intercept11\n",
    "#         detectedStdDev = stdDev11\n",
    "#     elif highestPearsonR == pearsonR12:\n",
    "#         detectedPeriod = self.periods[12]\n",
    "#         detectedSlope = slope12\n",
    "#         detectedIntrcpt = intercept12\n",
    "#         detectedStdDev = stdDev12\n",
    "#     elif highestPearsonR == pearsonR13:\n",
    "#         detectedPeriod = self.periods[13]\n",
    "#         detectedSlope = slope13\n",
    "#         detectedIntrcpt = intercept13\n",
    "#         detectedStdDev = stdDev13\n",
    "#     elif highestPearsonR == pearsonR14:\n",
    "#         detectedPeriod = self.periods[14]\n",
    "#         detectedSlope = slope14\n",
    "#         detectedIntrcpt = intercept14\n",
    "#         detectedStdDev = stdDev14\n",
    "#     elif highestPearsonR == pearsonR15:\n",
    "#         detectedPeriod = self.periods[15]\n",
    "#         detectedSlope = slope15\n",
    "#         detectedIntrcpt = intercept15\n",
    "#         detectedStdDev = stdDev15\n",
    "#     elif highestPearsonR == pearsonR16:\n",
    "#         detectedPeriod = self.periods[16]\n",
    "#         detectedSlope = slope16\n",
    "#         detectedIntrcpt = intercept16\n",
    "#         detectedStdDev = stdDev16\n",
    "#     elif highestPearsonR == pearsonR17:\n",
    "#         detectedPeriod = self.periods[17]\n",
    "#         detectedSlope = slope17\n",
    "#         detectedIntrcpt = intercept17\n",
    "#         detectedStdDev = stdDev17\n",
    "#     elif highestPearsonR == pearsonR18:\n",
    "#         detectedPeriod = self.periods[18]\n",
    "#         detectedSlope = slope18\n",
    "#         detectedIntrcpt = intercept18\n",
    "#         detectedStdDev = stdDev18\n",
    "#     elif highestPearsonR == pearsonR19:\n",
    "#         detectedPeriod = self.periods[19]\n",
    "#         detectedSlope = slope19\n",
    "#         detectedIntrcpt = intercept19\n",
    "#         detectedStdDev = stdDev19\n",
    "#     else:\n",
    "#         # Default case\n",
    "#         raise Exception(\"Cannot Find Highest PearsonR\") \n",
    "    \n",
    "#     # Calculate start and end price based on detected slope and intercept\n",
    "#     startPrice = math.exp(detectedIntrcpt + detectedSlope * (detectedPeriod - 1))\n",
    "#     endPrice = math.exp(detectedIntrcpt)\n",
    "#     startAtBar = len(dataframe) - detectedPeriod + 1\n",
    "\n",
    "#     # Calculate Upper Upper Price and Upper End price\n",
    "#     upperStartPrice = startPrice * math.exp(devMultiplier * detectedStdDev)\n",
    "#     upperEndPrice   =   endPrice * math.exp(devMultiplier * detectedStdDev)\n",
    "\n",
    "#     # Calculate Lower Price and Lower End Price\n",
    "#     lowerStartPrice = startPrice / math.exp(devMultiplier * detectedStdDev)\n",
    "#     lowerEndPrice =   endPrice / math.exp(devMultiplier * detectedStdDev)\n",
    "\n",
    "#     # Calculate If Uptrend or Downtrend and how strength is this trend\n",
    "#     # Also Know how many this trend exist with period\n",
    "#     # ====== Strategies ======\n",
    "#     # If EndPrice > StartPrice Uptrend\n",
    "#     # If EndPrice < StartPrice Downtrend\n",
    "#     trend_direction = endPrice - startPrice\n",
    "\n",
    "#     return trend_direction,detectedPeriod,highestPearsonR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqtrade download-data --exchange binance --pairs 1000BONK/USDT:USDT --timerange 20240106-20240107 -t 5m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
