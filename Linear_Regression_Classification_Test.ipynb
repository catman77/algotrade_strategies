{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close    4315.32\n",
      "high     4315.32\n",
      "Name: 39, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candle_number_to_calculate = 3\n",
    "\n",
    "def fetchCryptoData():\n",
    "    exchange = ccxt.binance()\n",
    "\n",
    "    symbol = 'BTC/USDT'\n",
    "    timeframe = '3m'\n",
    "\n",
    "    # Fetch OHLCV data (public data)\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe,20231001)\n",
    "\n",
    "    # Convert the data to a DataFrame\n",
    "    df = pd.DataFrame(ohlcv,columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "    # Convert timestamp to a human-readable format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # Drop the integer index column\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = fetchCryptoData()\n",
    "print(df.loc[39,['close','high']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, p):\n",
    "    min_val = x[-p:].min()\n",
    "    max_val = x[-p:].max()\n",
    "\n",
    "    scaled_column = (x - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_column\n",
    "\n",
    "def add_talib_indicators(data):\n",
    "    # RSI\n",
    "    data['rs'] = talib.RSI(data['close'], timeperiod=28)\n",
    "    data['rf'] = talib.RSI(data['close'], timeperiod=14)\n",
    "    # ROC\n",
    "    data['os'] = talib.ROC(data['close'], timeperiod=28)\n",
    "    data['of'] = talib.ROC(data['close'], timeperiod=14)\n",
    "\n",
    "    # CCI\n",
    "    data['cs'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=28)\n",
    "    data['cf'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=14)\n",
    "\n",
    "    # MOM\n",
    "    data['ms'] = scale(talib.MOM(data['close'], timeperiod=28),63) *100\n",
    "    data['mf'] = scale(talib.MOM(data['close'], timeperiod=14),63) *100\n",
    "\n",
    "    data['rs'] = np.nan_to_num(data['rs'])\n",
    "    data['os'] = np.nan_to_num(data['os'])\n",
    "    data['cs'] = np.nan_to_num(data['cs'])\n",
    "    data['ms'] = np.nan_to_num(data['ms'])\n",
    "\n",
    "    data['rf'] = np.nan_to_num(data['rf'])\n",
    "    data['of'] = np.nan_to_num(data['of'])\n",
    "    data['cf'] = np.nan_to_num(data['cf'])\n",
    "    data['mf'] = np.nan_to_num(data['mf'])\n",
    "\n",
    "    return data\n",
    "\n",
    "df = add_talib_indicators(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_1_slow(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rs']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['os']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cs']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['ms']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rs']+dataframe['os']+dataframe['cs']+dataframe['ms'])/4\n",
    "    \n",
    "\n",
    "def calculate_feature_2_fast(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rf']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['of']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cf']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['mf']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rf']+dataframe['of']+dataframe['cf']+dataframe['mf'])/4\n",
    "\n",
    "def calculate_regression_value(dataframe):\n",
    "    dataframe['actual_regression'] = -1 #Sell Signal\n",
    "    condition = (dataframe['close'].shift(-candle_number_to_calculate) - dataframe['close']) > 0\n",
    "    dataframe.loc[condition, 'actual_regression'] = 1 #Buy Signal\n",
    "    return dataframe['actual_regression']\n",
    "\n",
    "df['actual_regression'] = np.nan_to_num(calculate_regression_value(df))\n",
    "df['feature_slow'] = np.nan_to_num(calculate_feature_1_slow(\"All\",df))\n",
    "df['feature_fast'] = np.nan_to_num(calculate_feature_2_fast(\"All\",df))\n",
    "df['feature_combination'] = df['feature_slow'] * df['feature_fast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data And Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.534\n",
      "Training Accuracy : 0.6832151300236406 ===== Testing Accuracy : 0.8085106382978723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    # Generate some sample data\n",
    "    filter_index = df[(df['feature_slow'] == 0) | (df['feature_fast'] == 0)].index\n",
    "\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "    # Drop X 0 and last 3 candle\n",
    "    X = X.drop(filter_index)\n",
    "    X = X.iloc[:, X.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    # Drop Y 0 and last 3 candle\n",
    "    y = y.drop(filter_index)\n",
    "    y = y.iloc[:, y.columns.isin(['actual_regression'])]\n",
    "\n",
    "    test_data = df[['feature_slow', 'feature_fast','close','rs']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(\n",
    "                          kernel='rbf',\n",
    "                          C=100,\n",
    "                          gamma='auto',\n",
    "                          random_state=42,\n",
    "                          probability=True,\n",
    "                          cache_size=1,\n",
    "                          )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, \n",
    "                                      min_samples_leaf=50,\n",
    "                                      oob_score=True,\n",
    "                                      random_state=42)\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "                                                  ('svm', svm_classifier), \n",
    "                                                  ('rf', rf_model),\n",
    "                                                  ], voting='hard')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[450:500,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volatility_filter\n",
      " 1.0    37\n",
      "-1.0    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def volatilifyFilter(dataframe):\n",
    "    # Define BB windows \n",
    "    bb_window = 20\n",
    "    bb_dev = 2\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    upper_band , middle_band, lower_band = talib.BBANDS(dataframe['close'],timeperiod=bb_window,nbdevup=bb_dev,nbdevdn=bb_dev)\n",
    "\n",
    "    # Calculate ATR\n",
    "\n",
    "    # Define threshold for atr\n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] < lower_band)\n",
    "        ),\n",
    "        'volatility_filter'] = 1\n",
    "    \n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] > upper_band)\n",
    "        ),\n",
    "        'volatility_filter'] = -1\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df = volatilifyFilter(df)\n",
    "print(df['volatility_filter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftuser/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.948\n",
      "Training Accuracy : 0.5861297539149888 ===== Testing Accuracy : 0.6\n"
     ]
    }
   ],
   "source": [
    "# Second Model\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast'])]\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    test_data = df[['feature_slow', 'feature_fast']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(kernel='poly',\n",
    "                        C=100,\n",
    "                        gamma='auto',\n",
    "                        random_state=42,\n",
    "                        probability=True,\n",
    "                        tol=0.1,\n",
    "                        cache_size=1,\n",
    "                        max_iter=100,\n",
    "                        degree=3\n",
    "                        )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                      oob_score=True,\n",
    "                                      )\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[('svm', svm_classifier), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train_std, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[0:50,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              timestamp     open     high      low    close    volume  \\\n",
      "0   2017-08-17 04:00:00  4261.48  4280.56  4261.48  4280.56  2.036257   \n",
      "1   2017-08-17 04:03:00  4261.48  4261.48  4261.48  4261.48  0.152804   \n",
      "2   2017-08-17 04:06:00  4261.48  4261.48  4261.48  4261.48  0.000000   \n",
      "3   2017-08-17 04:09:00  4261.48  4261.48  4261.48  4261.48  0.000000   \n",
      "4   2017-08-17 04:12:00  4261.48  4261.48  4261.48  4261.48  0.000000   \n",
      "..                  ...      ...      ...      ...      ...       ...   \n",
      "495 2017-08-18 04:45:00  4292.39  4292.39  4284.74  4284.74  1.228851   \n",
      "496 2017-08-18 04:48:00  4284.74  4285.99  4271.02  4271.02  4.512253   \n",
      "497 2017-08-18 04:51:00  4271.02  4287.92  4271.02  4287.92  2.508703   \n",
      "498 2017-08-18 04:54:00  4287.92  4287.92  4287.92  4287.92  1.238955   \n",
      "499 2017-08-18 04:57:00  4287.92  4287.92  4287.92  4287.92  0.762707   \n",
      "\n",
      "       atr_low   atr_high  atr_filter  \n",
      "0          NaN        NaN       False  \n",
      "1          NaN        NaN       False  \n",
      "2          NaN        NaN       False  \n",
      "3          NaN        NaN       False  \n",
      "4          NaN        NaN       False  \n",
      "..         ...        ...         ...  \n",
      "495  15.032300  16.559619       False  \n",
      "496  15.026070  16.519879       False  \n",
      "497  15.213463  16.529382       False  \n",
      "498  13.692117  16.116147       False  \n",
      "499  12.322905  15.713244       False  \n",
      "\n",
      "[500 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# def adaptiveTrendFinder(self,dataframe:DataFrame):\n",
    "#     # Variable Can Modify\n",
    "#     devMultiplier = 2.0\n",
    "\n",
    "#     # Calculate Deviation,PersionR,Slope,Intercept\n",
    "#     stdDev01, pearsonR01, slope01, intercept01 = self.calcDev(self.periods[1],dataframe)\n",
    "#     stdDev02, pearsonR02, slope02, intercept02 = self.calcDev(self.periods[2],dataframe)\n",
    "#     stdDev03, pearsonR03, slope03, intercept03 = self.calcDev(self.periods[3],dataframe)\n",
    "#     stdDev04, pearsonR04, slope04, intercept04 = self.calcDev(self.periods[4],dataframe)\n",
    "#     stdDev05, pearsonR05, slope05, intercept05 = self.calcDev(self.periods[5],dataframe)\n",
    "#     stdDev06, pearsonR06, slope06, intercept06 = self.calcDev(self.periods[6],dataframe)\n",
    "#     stdDev07, pearsonR07, slope07, intercept07 = self.calcDev(self.periods[7],dataframe)\n",
    "#     stdDev08, pearsonR08, slope08, intercept08 = self.calcDev(self.periods[8],dataframe)\n",
    "#     stdDev09, pearsonR09, slope09, intercept09 = self.calcDev(self.periods[9],dataframe)\n",
    "#     stdDev10, pearsonR10, slope10, intercept10 = self.calcDev(self.periods[10],dataframe)\n",
    "#     stdDev11, pearsonR11, slope11, intercept11 = self.calcDev(self.periods[11],dataframe)\n",
    "#     stdDev12, pearsonR12, slope12, intercept12 = self.calcDev(self.periods[12],dataframe)\n",
    "#     stdDev13, pearsonR13, slope13, intercept13 = self.calcDev(self.periods[13],dataframe)\n",
    "#     stdDev14, pearsonR14, slope14, intercept14 = self.calcDev(self.periods[14],dataframe)\n",
    "#     stdDev15, pearsonR15, slope15, intercept15 = self.calcDev(self.periods[15],dataframe)\n",
    "#     stdDev16, pearsonR16, slope16, intercept16 = self.calcDev(self.periods[16],dataframe)\n",
    "#     stdDev17, pearsonR17, slope17, intercept17 = self.calcDev(self.periods[17],dataframe)\n",
    "#     stdDev18, pearsonR18, slope18, intercept18 = self.calcDev(self.periods[18],dataframe)\n",
    "#     stdDev19, pearsonR19, slope19, intercept19 = self.calcDev(self.periods[19],dataframe)\n",
    "\n",
    "#     # Find the highest Pearson's R\n",
    "#     # float highestPearsonR = pearsonR01\n",
    "#     highestPearsonR = max(pearsonR01, pearsonR02, pearsonR03, pearsonR04, pearsonR05, pearsonR06, pearsonR07, pearsonR08, pearsonR09, pearsonR10, pearsonR11, pearsonR12, pearsonR13, pearsonR14, pearsonR15, pearsonR16, pearsonR17, pearsonR18, pearsonR19)\n",
    "\n",
    "#     # Determine selected length, slope, intercept, and deviations\n",
    "#     detectedPeriod  = 0\n",
    "#     detectedSlope   = 0\n",
    "#     detectedIntrcpt = 0\n",
    "#     detectedStdDev  = 0\n",
    "\n",
    "#     if highestPearsonR == pearsonR01:\n",
    "#         detectedPeriod = self.periods[1]\n",
    "#         detectedSlope = slope01\n",
    "#         detectedIntrcpt = intercept01\n",
    "#         detectedStdDev = stdDev01\n",
    "#     elif highestPearsonR == pearsonR02:\n",
    "#         detectedPeriod = self.periods[2] \n",
    "#         detectedSlope = slope02\n",
    "#         detectedIntrcpt = intercept02\n",
    "#         detectedStdDev = stdDev02\n",
    "#     elif highestPearsonR == pearsonR03:\n",
    "#         detectedPeriod = self.periods[3]  \n",
    "#         detectedSlope = slope03\n",
    "#         detectedIntrcpt = intercept03\n",
    "#         detectedStdDev = stdDev03\n",
    "#     elif highestPearsonR == pearsonR04:\n",
    "#         detectedPeriod = self.periods[4]  \n",
    "#         detectedSlope = slope04\n",
    "#         detectedIntrcpt = intercept04\n",
    "#         detectedStdDev = stdDev04\n",
    "#     elif highestPearsonR == pearsonR05:\n",
    "#         detectedPeriod = self.periods[5]  \n",
    "#         detectedSlope = slope05\n",
    "#         detectedIntrcpt = intercept05\n",
    "#         detectedStdDev = stdDev05\n",
    "#     elif highestPearsonR == pearsonR06:\n",
    "#         detectedPeriod = self.periods[6]       \n",
    "#         detectedSlope = slope06\n",
    "#         detectedIntrcpt = intercept06\n",
    "#         detectedStdDev = stdDev06\n",
    "#     elif highestPearsonR == pearsonR07:\n",
    "#         detectedPeriod = self.periods[7]      \n",
    "#         detectedSlope = slope07\n",
    "#         detectedIntrcpt = intercept07\n",
    "#         detectedStdDev = stdDev07\n",
    "#     elif highestPearsonR == pearsonR08:\n",
    "#         detectedPeriod = self.periods[8]       \n",
    "#         detectedSlope = slope08\n",
    "#         detectedIntrcpt = intercept08\n",
    "#         detectedStdDev = stdDev08\n",
    "#     elif highestPearsonR == pearsonR09:\n",
    "#         detectedPeriod = self.periods[9]       \n",
    "#         detectedSlope = slope09\n",
    "#         detectedIntrcpt = intercept09\n",
    "#         detectedStdDev = stdDev09\n",
    "#     elif highestPearsonR == pearsonR10:\n",
    "#         detectedPeriod = self.periods[10]\n",
    "#         detectedSlope = slope10\n",
    "#         detectedIntrcpt = intercept10\n",
    "#         detectedStdDev = stdDev10\n",
    "#     elif highestPearsonR == pearsonR11:\n",
    "#         detectedPeriod = self.periods[11]\n",
    "#         detectedSlope = slope11\n",
    "#         detectedIntrcpt = intercept11\n",
    "#         detectedStdDev = stdDev11\n",
    "#     elif highestPearsonR == pearsonR12:\n",
    "#         detectedPeriod = self.periods[12]\n",
    "#         detectedSlope = slope12\n",
    "#         detectedIntrcpt = intercept12\n",
    "#         detectedStdDev = stdDev12\n",
    "#     elif highestPearsonR == pearsonR13:\n",
    "#         detectedPeriod = self.periods[13]\n",
    "#         detectedSlope = slope13\n",
    "#         detectedIntrcpt = intercept13\n",
    "#         detectedStdDev = stdDev13\n",
    "#     elif highestPearsonR == pearsonR14:\n",
    "#         detectedPeriod = self.periods[14]\n",
    "#         detectedSlope = slope14\n",
    "#         detectedIntrcpt = intercept14\n",
    "#         detectedStdDev = stdDev14\n",
    "#     elif highestPearsonR == pearsonR15:\n",
    "#         detectedPeriod = self.periods[15]\n",
    "#         detectedSlope = slope15\n",
    "#         detectedIntrcpt = intercept15\n",
    "#         detectedStdDev = stdDev15\n",
    "#     elif highestPearsonR == pearsonR16:\n",
    "#         detectedPeriod = self.periods[16]\n",
    "#         detectedSlope = slope16\n",
    "#         detectedIntrcpt = intercept16\n",
    "#         detectedStdDev = stdDev16\n",
    "#     elif highestPearsonR == pearsonR17:\n",
    "#         detectedPeriod = self.periods[17]\n",
    "#         detectedSlope = slope17\n",
    "#         detectedIntrcpt = intercept17\n",
    "#         detectedStdDev = stdDev17\n",
    "#     elif highestPearsonR == pearsonR18:\n",
    "#         detectedPeriod = self.periods[18]\n",
    "#         detectedSlope = slope18\n",
    "#         detectedIntrcpt = intercept18\n",
    "#         detectedStdDev = stdDev18\n",
    "#     elif highestPearsonR == pearsonR19:\n",
    "#         detectedPeriod = self.periods[19]\n",
    "#         detectedSlope = slope19\n",
    "#         detectedIntrcpt = intercept19\n",
    "#         detectedStdDev = stdDev19\n",
    "#     else:\n",
    "#         # Default case\n",
    "#         raise Exception(\"Cannot Find Highest PearsonR\") \n",
    "    \n",
    "#     # Calculate start and end price based on detected slope and intercept\n",
    "#     startPrice = math.exp(detectedIntrcpt + detectedSlope * (detectedPeriod - 1))\n",
    "#     endPrice = math.exp(detectedIntrcpt)\n",
    "#     startAtBar = len(dataframe) - detectedPeriod + 1\n",
    "\n",
    "#     # Calculate Upper Upper Price and Upper End price\n",
    "#     upperStartPrice = startPrice * math.exp(devMultiplier * detectedStdDev)\n",
    "#     upperEndPrice   =   endPrice * math.exp(devMultiplier * detectedStdDev)\n",
    "\n",
    "#     # Calculate Lower Price and Lower End Price\n",
    "#     lowerStartPrice = startPrice / math.exp(devMultiplier * detectedStdDev)\n",
    "#     lowerEndPrice =   endPrice / math.exp(devMultiplier * detectedStdDev)\n",
    "\n",
    "#     # Calculate If Uptrend or Downtrend and how strength is this trend\n",
    "#     # Also Know how many this trend exist with period\n",
    "#     # ====== Strategies ======\n",
    "#     # If EndPrice > StartPrice Uptrend\n",
    "#     # If EndPrice < StartPrice Downtrend\n",
    "#     trend_direction = endPrice - startPrice\n",
    "\n",
    "#     return trend_direction,detectedPeriod,highestPearsonR\n",
    "df['atr_low'] = talib.ATR(df['high'],df['low'],df['close'],timeperiod=10)\n",
    "df['atr_high'] = talib.ATR(df['high'],df['low'],df['close'],timeperiod=40)\n",
    "df['atr_filter'] = df['atr_low'] > df['atr_high']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column_1  Column2\n",
      "0         1      1.0\n",
      "1        -1      0.0\n",
      "2        -1     -1.0\n",
      "3         1      0.0\n",
      "4        -1     -1.0\n",
      "5         1     -1.0\n",
      "6         1      1.0\n",
      "7         1      3.0\n",
      "8        -1      1.0\n",
      "9        -1      1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Pandas DataFrame with random data containing -1 and 1\n",
    "data = {'Column_1': np.random.choice([-1, 1], size=10)}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Column2'] = df['Column_1'].rolling(window=5, min_periods=1).sum()\n",
    "print(df)\n",
    "\n",
    "# def custom_exit(self, pair: str, trade: 'Trade', current_time: 'datetime', current_rate: float,\n",
    "#                 current_profit: float, **kwargs):\n",
    "#     dataframe, _ = self.dp.get_analyzed_dataframe(pair, self.timeframe)\n",
    "#     last_candle = dataframe.iloc[-1].squeeze()\n",
    "\n",
    "#     # Sell any positions at a loss if they are losing in 10 minutes.\n",
    "#     if current_profit < 0 and ((current_time - trade.open_date_utc).seconds >= 900):\n",
    "#         return 'unclog'\n",
    "    \n",
    "# def confirm_trade_exit(self, pair: str, trade: Trade, order_type: str, amount: float,\n",
    "#                         rate: float, time_in_force: str, exit_reason: str,\n",
    "#                         current_time: datetime, **kwargs) -> bool:\n",
    "    \n",
    "#     if  trade.calc_profit_ratio(rate) < 0 and (current_time - trade.open_date_utc).seconds >= 150:\n",
    "#         return True\n",
    "#     if trade.calc_profit_ratio(rate) < 0:\n",
    "#         return False\n",
    "#     return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
