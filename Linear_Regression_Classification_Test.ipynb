{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close    4315.32\n",
      "high     4315.32\n",
      "Name: 39, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candle_number_to_calculate = 3\n",
    "\n",
    "def fetchCryptoData():\n",
    "    exchange = ccxt.binance()\n",
    "\n",
    "    symbol = 'BTC/USDT'\n",
    "    timeframe = '3m'\n",
    "\n",
    "    # Fetch OHLCV data (public data)\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe,20231001)\n",
    "\n",
    "    # Convert the data to a DataFrame\n",
    "    df = pd.DataFrame(ohlcv,columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "    # Convert timestamp to a human-readable format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # Drop the integer index column\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = fetchCryptoData()\n",
    "print(df.loc[39,['close','high']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, p):\n",
    "    min_val = x[-p:].min()\n",
    "    max_val = x[-p:].max()\n",
    "\n",
    "    scaled_column = (x - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_column\n",
    "\n",
    "def add_talib_indicators(data):\n",
    "    # RSI\n",
    "    data['rs'] = talib.RSI(data['close'], timeperiod=28)\n",
    "    data['rf'] = talib.RSI(data['close'], timeperiod=14)\n",
    "    # ROC\n",
    "    data['os'] = talib.ROC(data['close'], timeperiod=28)\n",
    "    data['of'] = talib.ROC(data['close'], timeperiod=14)\n",
    "\n",
    "    # CCI\n",
    "    data['cs'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=28)\n",
    "    data['cf'] = talib.CCI(data['high'], data['low'], data['close'], timeperiod=14)\n",
    "\n",
    "    # MOM\n",
    "    data['ms'] = scale(talib.MOM(data['close'], timeperiod=28),63) *100\n",
    "    data['mf'] = scale(talib.MOM(data['close'], timeperiod=14),63) *100\n",
    "\n",
    "    data['rs'] = np.nan_to_num(data['rs'])\n",
    "    data['os'] = np.nan_to_num(data['os'])\n",
    "    data['cs'] = np.nan_to_num(data['cs'])\n",
    "    data['ms'] = np.nan_to_num(data['ms'])\n",
    "\n",
    "    data['rf'] = np.nan_to_num(data['rf'])\n",
    "    data['of'] = np.nan_to_num(data['of'])\n",
    "    data['cf'] = np.nan_to_num(data['cf'])\n",
    "    data['mf'] = np.nan_to_num(data['mf'])\n",
    "\n",
    "    return data\n",
    "\n",
    "df = add_talib_indicators(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_1_slow(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rs']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['os']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cs']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['ms']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rs']+dataframe['os']+dataframe['cs']+dataframe['ms'])/4\n",
    "    \n",
    "\n",
    "def calculate_feature_2_fast(ind,dataframe):\n",
    "\n",
    "    if ind == 'RSI':\n",
    "        return dataframe['rf']\n",
    "    elif ind == 'ROC':\n",
    "        return dataframe['of']\n",
    "    elif ind == 'CCI':\n",
    "        return dataframe['cf']\n",
    "    elif ind == 'MOM':\n",
    "        return dataframe['mf']\n",
    "    else:\n",
    "        # Assuming avg is a function that calculates the average\n",
    "        return (dataframe['rf']+dataframe['of']+dataframe['cf']+dataframe['mf'])/4\n",
    "\n",
    "def calculate_regression_value(dataframe):\n",
    "    dataframe['actual_regression'] = -1 #Sell Signal\n",
    "    condition = (dataframe['close'].shift(-candle_number_to_calculate) - dataframe['close']) > 0\n",
    "    dataframe.loc[condition, 'actual_regression'] = 1 #Buy Signal\n",
    "    return dataframe['actual_regression']\n",
    "\n",
    "df['actual_regression'] = np.nan_to_num(calculate_regression_value(df))\n",
    "df['feature_slow'] = np.nan_to_num(calculate_feature_1_slow(\"All\",df))\n",
    "df['feature_fast'] = np.nan_to_num(calculate_feature_2_fast(\"All\",df))\n",
    "df['feature_combination'] = df['feature_slow'] * df['feature_fast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data And Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.534\n",
      "Training Accuracy : 0.6832151300236406 ===== Testing Accuracy : 0.8085106382978723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    # Generate some sample data\n",
    "    filter_index = df[(df['feature_slow'] == 0) | (df['feature_fast'] == 0)].index\n",
    "\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "    # Drop X 0 and last 3 candle\n",
    "    X = X.drop(filter_index)\n",
    "    X = X.iloc[:, X.columns.isin(['feature_slow', 'feature_fast','close','rs'])]\n",
    "\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    # Drop Y 0 and last 3 candle\n",
    "    y = y.drop(filter_index)\n",
    "    y = y.iloc[:, y.columns.isin(['actual_regression'])]\n",
    "\n",
    "    test_data = df[['feature_slow', 'feature_fast','close','rs']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(\n",
    "                          kernel='rbf',\n",
    "                          C=100,\n",
    "                          gamma='auto',\n",
    "                          random_state=42,\n",
    "                          probability=True,\n",
    "                          cache_size=1,\n",
    "                          )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, \n",
    "                                      min_samples_leaf=50,\n",
    "                                      oob_score=True,\n",
    "                                      random_state=42)\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "                                                  ('svm', svm_classifier), \n",
    "                                                  ('rf', rf_model),\n",
    "                                                  ], voting='hard')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[450:500,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volatility_filter\n",
      " 1.0    37\n",
      "-1.0    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def volatilifyFilter(dataframe):\n",
    "    # Define BB windows \n",
    "    bb_window = 20\n",
    "    bb_dev = 2\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    upper_band , middle_band, lower_band = talib.BBANDS(dataframe['close'],timeperiod=bb_window,nbdevup=bb_dev,nbdevdn=bb_dev)\n",
    "\n",
    "    # Calculate ATR\n",
    "\n",
    "    # Define threshold for atr\n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] < lower_band)\n",
    "        ),\n",
    "        'volatility_filter'] = 1\n",
    "    \n",
    "    dataframe.loc[\n",
    "        (\n",
    "            (dataframe['close'] > upper_band)\n",
    "        ),\n",
    "        'volatility_filter'] = -1\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df = volatilifyFilter(df)\n",
    "print(df['volatility_filter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftuser/.local/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy : 0.948\n",
      "Training Accuracy : 0.5861297539149888 ===== Testing Accuracy : 0.6\n"
     ]
    }
   ],
   "source": [
    "# Second Model\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainModel(df):\n",
    "    X = df.iloc[:-candle_number_to_calculate, df.columns.isin(['feature_slow', 'feature_fast'])]\n",
    "    y = df.iloc[:-candle_number_to_calculate, df.columns.isin(['actual_regression'])]\n",
    "    test_data = df[['feature_slow', 'feature_fast']]\n",
    "\n",
    "    # Convert X_train and X_test to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.ravel(y)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_test_std = scaler.transform(test_data)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    svm_classifier = SVC(kernel='poly',\n",
    "                        C=100,\n",
    "                        gamma='auto',\n",
    "                        random_state=42,\n",
    "                        probability=True,\n",
    "                        tol=0.1,\n",
    "                        cache_size=1,\n",
    "                        max_iter=100,\n",
    "                        degree=3\n",
    "                        )\n",
    "    \n",
    "    # Ensemble Model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                      oob_score=True,\n",
    "                                      )\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=[('svm', svm_classifier), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "    # Train the classifier\n",
    "    ensemble_model.fit(X_train_std, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = ensemble_model.predict(X_test_std)\n",
    "    df['predicted_regression'] = y_pred\n",
    "\n",
    "    # print(df.iloc[0:50,[14,18]])\n",
    "\n",
    "    # Calculate accuray of buy and sell\n",
    "    accuracy = accuracy_score((df['actual_regression']>0).tolist(), (df['predicted_regression']>0).tolist())\n",
    "    print(f'Average Accuracy : {accuracy}')\n",
    "\n",
    "    train_accuracy = ensemble_model.score(X_train, y_train)\n",
    "    test_accuracy = ensemble_model.score(X_test, y_test)\n",
    "    print(f'Training Accuracy : {train_accuracy} =====',f'Testing Accuracy : {test_accuracy}')\n",
    "\n",
    "trainModel(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
